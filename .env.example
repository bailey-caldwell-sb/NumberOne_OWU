# =============================================================================
# NumberOne OWU - Environment Configuration
# =============================================================================
# Copy this file to .env and update with your actual values
# Most settings have sensible defaults and are optional

# =============================================================================
# AI Provider API Keys (Optional - for cloud models)
# =============================================================================

# Anthropic Claude API Key
# Get from: https://console.anthropic.com/
# Used for: Research tasks with Claude 3.5 Sonnet
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI API Key  
# Get from: https://platform.openai.com/api-keys
# Used for: GPT-4 and other OpenAI models
OPENAI_API_KEY=your_openai_api_key_here

# Perplexity API Key
# Get from: https://www.perplexity.ai/settings/api
# Used for: Real-time web search capabilities
PERPLEXITY_API_KEY=your_perplexity_api_key_here

# NumberOne AI API Key (if available)
# Get from: https://numberone.ai/
# Used for: Custom NumberOne AI models
NUMBERONE_API_KEY=your_numberone_api_key_here

# =============================================================================
# Ollama Configuration (Local AI Models)
# =============================================================================

# Ollama server host and port
# Default: localhost:11434 (auto-configured in Docker)
OLLAMA_HOST=localhost:11434

# How long to keep models loaded in memory
# Options: 5m, 10m, 1h, -1 (forever)
# Default: 5m (good balance of performance and memory usage)
OLLAMA_KEEP_ALIVE=5m

# =============================================================================
# Memory System Configuration (Mem0)
# =============================================================================

# User identifier for memory isolation
# Each user gets their own memory space
# Default: bailey
MEM0_USER=bailey

# Number of messages before storing to memory
# Lower = more frequent storage, higher = less frequent
# Default: 3 (good balance)
MEM0_STORE_CYCLES=3

# Memory model configuration
# These should match your Ollama models
MEM0_LLM_MODEL=qwen2.5:7b
MEM0_EMBEDDER_MODEL=nomic-embed-text:latest

# =============================================================================
# Langfuse Configuration (LLM Observability)
# =============================================================================

# Langfuse secret keys (generate random strings)
# Used for API authentication and session security
LANGFUSE_SECRET=your-secret-key-here-32-chars-min
LANGFUSE_SALT=your-salt-here-16-chars-min

# Langfuse API keys (optional - for external tracking)
# Get from: Langfuse dashboard after setup
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key

# =============================================================================
# Open WebUI Configuration
# =============================================================================

# WebUI branding and customization
WEBUI_NAME=NumberOne OWU
WEBUI_SECRET_KEY=your-webui-secret-key-here

# Default user role for new registrations
# Options: admin, user, pending
# Default: user (recommended for security)
DEFAULT_USER_ROLE=user

# Authentication settings
# Set to false to disable user authentication (not recommended)
WEBUI_AUTH=true

# =============================================================================
# Security Settings
# =============================================================================

# Enable/disable various security features
ENABLE_SIGNUP=true
ENABLE_LOGIN_FORM=true
ENABLE_WEB_BROWSE=true

# CORS settings (usually auto-configured)
CORS_ALLOW_ORIGIN=*

# =============================================================================
# Performance & Resource Settings
# =============================================================================

# Docker resource limits (optional)
# Uncomment and adjust based on your system

# Maximum memory for Ollama (in GB)
# OLLAMA_MAX_MEMORY=8

# Maximum memory for Open WebUI (in MB)
# OPENWEBUI_MAX_MEMORY=2048

# Number of CPU cores to use
# DOCKER_CPU_LIMIT=4

# =============================================================================
# Feature Flags
# =============================================================================

# Enable/disable specific features
ENABLE_RAG_HYBRID_SEARCH=true
ENABLE_RAG_WEB_LOADER=true
ENABLE_IMAGE_GENERATION=false
ENABLE_COMMUNITY_SHARING=false

# Experimental features
ENABLE_EXPERIMENTAL_FEATURES=true

# =============================================================================
# Database Configuration (Auto-configured)
# =============================================================================
# These are automatically set by Docker Compose
# Only modify if you're using external databases

# Qdrant vector database
QDRANT_HOST=qdrant
QDRANT_PORT=6333

# PostgreSQL for Langfuse
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=langfuse

# ClickHouse for Langfuse analytics
CLICKHOUSE_USER=langfuse
CLICKHOUSE_PASSWORD=langfuse
CLICKHOUSE_DB=langfuse

# =============================================================================
# Development Settings (Optional)
# =============================================================================

# Enable debug logging
DEBUG_MODE=false

# Log level for all services
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable development features
DEV_MODE=false

# =============================================================================
# Backup & Storage Settings
# =============================================================================

# Backup configuration
BACKUP_ENABLED=true
BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM
BACKUP_RETENTION_DAYS=30

# Storage paths (auto-configured in Docker)
DATA_DIR=/app/data
BACKUP_DIR=/app/backups

# =============================================================================
# Monitoring & Analytics
# =============================================================================

# Enable system monitoring
MONITORING_ENABLED=true

# Metrics collection interval (seconds)
METRICS_INTERVAL=60

# Enable usage analytics (anonymous)
ANALYTICS_ENABLED=false

# =============================================================================
# Network Configuration (Auto-configured)
# =============================================================================
# These ports are automatically configured by Docker Compose
# Only modify if you have port conflicts

# Open WebUI port
WEBUI_PORT=3000

# Langfuse port
LANGFUSE_PORT=3003

# Ollama port
OLLAMA_PORT=11434

# Qdrant ports
QDRANT_HTTP_PORT=6333
QDRANT_GRPC_PORT=6334

# Pipelines port
PIPELINES_PORT=9099

# Dashboard port
DASHBOARD_PORT=8080

# =============================================================================
# Advanced Configuration
# =============================================================================

# Custom model configurations (JSON format)
# CUSTOM_MODELS='{"model1": {"name": "Custom Model", "provider": "ollama"}}'

# Pipeline configurations
# PIPELINE_CONFIGS='{"mem0": {"enabled": true}, "langfuse": {"enabled": true}}'

# Integration settings
# INTEGRATION_CONFIGS='{"perplexity": {"enabled": true, "model": "sonar-pro"}}'
